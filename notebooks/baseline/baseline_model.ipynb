{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:00:56.426001Z",
     "start_time": "2023-09-17T13:00:56.095043100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/speech_emotion_recognition_kagle/Savee\n"
     ]
    }
   ],
   "source": [
    "image_dir = Path('../dataset/speech_emotion_recognition_kagle/Savee')\n",
    "\n",
    "print(image_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:00:56.428001900Z",
     "start_time": "2023-09-17T13:00:56.419006200Z"
    }
   },
   "id": "b945a1d67e7abce6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "PosixPath('../dataset/speech_emotion_recognition_kagle/Savee/DC_n13.wav')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths = list(image_dir.glob(r'**/*.wav'))\n",
    "filepaths[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:00:56.444882100Z",
     "start_time": "2023-09-17T13:00:56.428001900Z"
    }
   },
   "id": "d05a0c72b7be1cf1"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "labels = list(map(lambda x: os.path.split(x)[1].split('/')[0].split('_')[1].split('.')[0], filepaths))\n",
    "labels = [re.sub('[^a-zA-Z]+', '', label) for label in labels]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:12:34.220984900Z",
     "start_time": "2023-09-17T13:12:34.174073100Z"
    }
   },
   "id": "cda914322f83f379"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Filepath Label\n0    ../dataset/speech_emotion_recognition_kagle/Sa...     n\n1    ../dataset/speech_emotion_recognition_kagle/Sa...    su\n2    ../dataset/speech_emotion_recognition_kagle/Sa...     a\n3    ../dataset/speech_emotion_recognition_kagle/Sa...     f\n4    ../dataset/speech_emotion_recognition_kagle/Sa...    sa\n..                                                 ...   ...\n475  ../dataset/speech_emotion_recognition_kagle/Sa...    su\n476  ../dataset/speech_emotion_recognition_kagle/Sa...     a\n477  ../dataset/speech_emotion_recognition_kagle/Sa...     d\n478  ../dataset/speech_emotion_recognition_kagle/Sa...     n\n479  ../dataset/speech_emotion_recognition_kagle/Sa...     h\n\n[480 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filepath</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>su</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>f</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>sa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>su</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>d</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>n</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>h</td>\n    </tr>\n  </tbody>\n</table>\n<p>480 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "\n",
    "audio_df = pd.concat([filepaths, labels], axis=1)\n",
    "audio_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:12:34.434321100Z",
     "start_time": "2023-09-17T13:12:34.426025400Z"
    }
   },
   "id": "f0e0da71e78acbc6"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'a', 'd', 'f', 'h', 'n', 'sa', 'su'}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:12:34.827457400Z",
     "start_time": "2023-09-17T13:12:34.819159100Z"
    }
   },
   "id": "c837ead8cc4509b"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Filepath Label\n0    ../dataset/speech_emotion_recognition_kagle/Sa...   NEU\n1    ../dataset/speech_emotion_recognition_kagle/Sa...   SUP\n2    ../dataset/speech_emotion_recognition_kagle/Sa...   ANG\n3    ../dataset/speech_emotion_recognition_kagle/Sa...   FEA\n4    ../dataset/speech_emotion_recognition_kagle/Sa...   SAD\n..                                                 ...   ...\n475  ../dataset/speech_emotion_recognition_kagle/Sa...   SUP\n476  ../dataset/speech_emotion_recognition_kagle/Sa...   ANG\n477  ../dataset/speech_emotion_recognition_kagle/Sa...   DIS\n478  ../dataset/speech_emotion_recognition_kagle/Sa...   NEU\n479  ../dataset/speech_emotion_recognition_kagle/Sa...   HAP\n\n[480 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filepath</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>SUP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>ANG</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>FEA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>SAD</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>SUP</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>ANG</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>DIS</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>NEU</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>../dataset/speech_emotion_recognition_kagle/Sa...</td>\n      <td>HAP</td>\n    </tr>\n  </tbody>\n</table>\n<p>480 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df.replace(['a', 'd', 'f', 'h', 'n', 'sa', 'su']\n",
    "                 , ['ANG','DIS', 'FEA','HAP', 'NEU', 'SAD', 'SUP'], inplace=True)\n",
    "audio_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:12:35.244560600Z",
     "start_time": "2023-09-17T13:12:35.235561Z"
    }
   },
   "id": "97131039837ec7fb"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(480, 480, 1)), # Adjust input shape as needed\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(labels), activation='softmax') # 7 emotions (adjust as needed)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define a function to preprocess the audio data (you may need to install librosa)\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_audio(file_path):\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    spectrogram = np.expand_dims(spectrogram, axis=-1)\n",
    "    return spectrogram"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:22:43.261693600Z",
     "start_time": "2023-09-17T13:22:40.315939200Z"
    }
   },
   "id": "c29ca8e038f8ea50"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128\n  y sizes: 480\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[80], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/VoiceMonet/notebooks/baseline/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/dev/VoiceMonet/notebooks/baseline/venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1950\u001B[0m, in \u001B[0;36m_check_data_cardinality\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1943\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m sizes: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1944\u001B[0m         label,\n\u001B[1;32m   1945\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m   1946\u001B[0m             \u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(single_data)\n\u001B[1;32m   1947\u001B[0m         ),\n\u001B[1;32m   1948\u001B[0m     )\n\u001B[1;32m   1949\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMake sure all arrays contain the same number of samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1950\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[0;31mValueError\u001B[0m: Data cardinality is ambiguous:\n  x sizes: 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128\n  y sizes: 480\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:22:44.405894Z",
     "start_time": "2023-09-17T13:22:43.254608800Z"
    }
   },
   "id": "51fabad1b9edeafd"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:12:40.297437400Z",
     "start_time": "2023-09-17T13:12:40.248449400Z"
    }
   },
   "id": "17774a4a1706906c"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:25:12.234579500Z",
     "start_time": "2023-09-17T13:25:12.038838700Z"
    }
   },
   "id": "9d6cd537047f96f5"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:25:13.556907600Z",
     "start_time": "2023-09-17T13:25:13.554909700Z"
    }
   },
   "id": "8f28446ff56f31c1"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[89], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mx_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m, y_train\u001B[38;5;241m.\u001B[39mshape, x_test\u001B[38;5;241m.\u001B[39mshape, y_test\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:25:39.230089900Z",
     "start_time": "2023-09-17T13:25:39.193192900Z"
    }
   },
   "id": "e943efabe83d1201"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(y).reshape(-1,1)).toarray()\n",
    "Y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:21:46.067753600Z",
     "start_time": "2023-09-17T13:21:46.036921600Z"
    }
   },
   "id": "c710d77781817f61"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "# \n",
    "for _, example in audio_df.iterrows():\n",
    "    spectrogram = preprocess_audio(example['Filepath'])\n",
    "    X.append(spectrogram)\n",
    "    y.append(example['Label'])\n",
    "\n",
    "\n",
    "# X_train.append(spectrogram['Filepath'][:350])\n",
    "# y_train.append(spectrogram['Label'][:350])\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# \n",
    "model.fit(X_train, y_train, epochs=1)\n",
    "# \n",
    "# \n",
    "# test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "# print(f'Test accuracy: {test_acc}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:17:30.912682200Z",
     "start_time": "2023-09-17T13:17:23.484085600Z"
    }
   },
   "id": "158fba72bc615f02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "abff86077cf5bb5e"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (480, 128) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m X_train \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# y_train = np.array(y)\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (480, 128) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "X_train = np.array(X)\n",
    "# y_train = np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:18:18.067838200Z",
     "start_time": "2023-09-17T13:18:18.043756700Z"
    }
   },
   "id": "51791445c3906240"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128\n  y sizes: 480\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/VoiceMonet/notebooks/baseline/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/dev/VoiceMonet/notebooks/baseline/venv/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1950\u001B[0m, in \u001B[0;36m_check_data_cardinality\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m   1943\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m sizes: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1944\u001B[0m         label,\n\u001B[1;32m   1945\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m   1946\u001B[0m             \u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mflatten(single_data)\n\u001B[1;32m   1947\u001B[0m         ),\n\u001B[1;32m   1948\u001B[0m     )\n\u001B[1;32m   1949\u001B[0m msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMake sure all arrays contain the same number of samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1950\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[0;31mValueError\u001B[0m: Data cardinality is ambiguous:\n  x sizes: 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128\n  y sizes: 480\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T13:22:17.709193900Z",
     "start_time": "2023-09-17T13:22:17.585854300Z"
    }
   },
   "id": "8fcf749eb02b55ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "88edc15744b7c361"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
